{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f70e4e4-e34a-4a63-a90c-4dd6186afadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Conversation, pipeline, TrainingArguments, Trainer, Seq2SeqTrainer\n",
    "from datasets import load_metric\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a416cf-ede2-403d-bb51-954aac8efdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/intent_Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ce4946-dfb0-4332-9ab8-f568cab80a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets = df[df['airline_sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d056a8e1-296f-408c-821e-c150b899a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40e98038fb546bc9044d2ddc106d43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3c4cee11bd4dd39d6e9f937f4f0df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753029b9497b40d1a73c4a947f4a4956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c88c520a91540658eef2d5116d23d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3c152409e849538392d82fad6c6348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce83115d51a244f98f56cac04277feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/GODEL-v1_1-large-seq2seq')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('microsoft/GODEL-v1_1-large-seq2seq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0268e44e-5b0c-449d-ab23-72ca50e1f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_tweet(text, tk, m, i, k):\n",
    "    if k != '':\n",
    "        k = '[KNOWLEDGE] ' + k\n",
    "    if text != '':\n",
    "        text = f'[CONTEXT] {text}'\n",
    "    query = f'{i} {text} {k}'\n",
    "    encoding = tk.encode(f'{query}', return_tensors='pt')\n",
    "    outputs = m.generate(encoding, max_length=140, min_length=8, top_p=.9, do_sample=True)\n",
    "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8792696-15db-44a5-80e9-f5d141d829e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can help you book a new flight. Do this as a passenger to ensure a safe flight home.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the playground to test the base model\n",
    "instruction = 'Instruction: As an airline help representative, help the person book a new flight'\n",
    "tweet = f'My flight was cancelled from Houston to New York and I need help getting home'\n",
    "knowledge = 'there is an available flight at 8pm'\n",
    "respond_to_tweet(tweet, tokenizer, model, instruction, knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d510988-997a-488d-8549-dcc987c337c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_to_int(intent):\n",
    "    intents = [\n",
    "        'Bad Flight',\n",
    "        'Can\\'t Tell',\n",
    "        'Late Flight',\n",
    "        'Customer Service Issue',\n",
    "        'Flight Booking Problem',\n",
    "        'Lost Luggage',\n",
    "        'Flight Attendant Complaint',\n",
    "        'Cancelled Flight',\n",
    "        'Damaged Luggage'\n",
    "    ]\n",
    "    try:\n",
    "        idx = intents.index(intent)\n",
    "        return idx\n",
    "    except:\n",
    "        return f'Value not found: {intent} is not a valid intent'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d753be5-a90f-4b7c-b417-4c5bd60464fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>response_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica it is really aggressive to blas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>Sorry! We will try to ensure the audio isn’t t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570276917301137409</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heatherovieda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica i flew from nyc to sfo last wee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 09:39:46 -0800</td>\n",
       "      <td>this place called NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>That’s the luck of the draw I guess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>570265883513384960</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSGJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica why are your first fares in may...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 08:55:56 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sorry it’s so expensive right now! Gas prices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>570256553502068736</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ayeevickiee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica you guys messed up my seating i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 08:18:51 -0800</td>\n",
       "      <td>714</td>\n",
       "      <td>Mountain Time (US &amp; Canada)</td>\n",
       "      <td>So sorry about that! We’ll be sure to make sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>570249102404923392</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leora13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica status match program i applied ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 07:49:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You should be hearing back soon, thank you for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id  airline_sentiment  \\\n",
       "0           0  570301031407624196                 -1   \n",
       "4           4  570276917301137409                 -1   \n",
       "5           5  570265883513384960                 -1   \n",
       "6           6  570256553502068736                 -1   \n",
       "7           7  570249102404923392                 -1   \n",
       "\n",
       "   airline_sentiment_confidence          negativereason  \\\n",
       "0                        1.0000              Bad Flight   \n",
       "4                        1.0000              Bad Flight   \n",
       "5                        0.6705              Can't Tell   \n",
       "6                        1.0000  Customer Service Issue   \n",
       "7                        1.0000  Customer Service Issue   \n",
       "\n",
       "   negativereason_confidence         airline airline_sentiment_gold  \\\n",
       "0                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "5                     0.3614  Virgin America                    NaN   \n",
       "6                     0.3557  Virgin America                    NaN   \n",
       "7                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0       jnardino                 NaN              0   \n",
       "4  heatherovieda                 NaN              0   \n",
       "5         MISSGJ                 NaN              0   \n",
       "6    ayeevickiee                 NaN              0   \n",
       "7        Leora13                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0   virginamerica it is really aggressive to blas...         NaN   \n",
       "4   virginamerica i flew from nyc to sfo last wee...         NaN   \n",
       "5   virginamerica why are your first fares in may...         NaN   \n",
       "6   virginamerica you guys messed up my seating i...         NaN   \n",
       "7   virginamerica status match program i applied ...         NaN   \n",
       "\n",
       "               tweet_created         tweet_location  \\\n",
       "0  2015-02-24 11:15:36 -0800                    NaN   \n",
       "4  2015-02-24 09:39:46 -0800  this place called NYC   \n",
       "5  2015-02-24 08:55:56 -0800                    NaN   \n",
       "6  2015-02-24 08:18:51 -0800                    714   \n",
       "7  2015-02-24 07:49:15 -0800                    NaN   \n",
       "\n",
       "                 user_timezone  \\\n",
       "0   Pacific Time (US & Canada)   \n",
       "4   Eastern Time (US & Canada)   \n",
       "5                          NaN   \n",
       "6  Mountain Time (US & Canada)   \n",
       "7                          NaN   \n",
       "\n",
       "                                      response_label  \n",
       "0  Sorry! We will try to ensure the audio isn’t t...  \n",
       "4               That’s the luck of the draw I guess.  \n",
       "5  Sorry it’s so expensive right now! Gas prices ...  \n",
       "6  So sorry about that! We’ll be sure to make sur...  \n",
       "7  You should be hearing back soon, thank you for...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posttrain_tweets = neg_tweets[neg_tweets['response_label'].notnull()]\n",
    "posttrain_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f5e27c-c092-4b97-a820-384093733eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_posttrain(posttrain, field):\n",
    "    return posttrain[field].map(lambda t: tokenizer(t, padding='max_length', truncation=True, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623429cb-e578-468d-bddd-655617003bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tweet_input(context, text):\n",
    "    text = f\"[KNOWLEDGE] {text}\"\n",
    "    i = intent_to_int(context)\n",
    "    if i == 0:\n",
    "        return f'Instruction: Ask the person how you can help in the future {text} [CONTEXT] {context}'\n",
    "    elif i == 1:\n",
    "        return f'Instruction: Ask the person how the airline can do better {text}'\n",
    "    elif i == 2:\n",
    "        return f'Instruction: Thank the person for their patience, see if they want to switch flights {text} [CONTEXT] {context}'\n",
    "    elif i == 3:\n",
    "        return f'Instruction: See if there is anything you can do to help {text} [CONTEXT] {context}'\n",
    "    elif i == 4:\n",
    "        return f'Instruction: Offer to help with booking the flight {text} [CONTEXT] {context}'\n",
    "    elif i == 5:\n",
    "        return f'Instruction: Ask the customer where their luggage is coming from and for the receipt number {text} [CONTEXT] {context}'\n",
    "    elif i == 6:\n",
    "        return f'Instruction: Ask the customer what flight they were on {text} [CONTEXT] {context}'\n",
    "    elif i == 7:\n",
    "        return f'Instruction: Offer to book another flight for the customer {text} [CONTEXT] {context}'\n",
    "    elif i == 8:\n",
    "        return f'Instruction: Ask the customer where their luggage is coming from and for the receipt number {text} [CONTEXT] {context}'\n",
    "    else:\n",
    "        return f'Instruction: Ask if there is anything you can do'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1fc239-4903-4a44-ac45-4a7246a18e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text                       labels\n",
       "0  [input_ids, attention_mask]  [input_ids, attention_mask]\n",
       "4  [input_ids, attention_mask]  [input_ids, attention_mask]\n",
       "5  [input_ids, attention_mask]  [input_ids, attention_mask]\n",
       "6  [input_ids, attention_mask]  [input_ids, attention_mask]\n",
       "7  [input_ids, attention_mask]  [input_ids, attention_mask]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posttrain_tweets['embeddings'] = posttrain_tweets.apply(lambda x: create_tweet_input(x['negativereason'], x['text']), axis=1)\n",
    "# print(tokenize_posttrain(posttrain_tweets, 'embeddings')[0])\n",
    "# print(posttrain_tweets['embeddings'].map(lambda text: tokenizer.encode(text)))\n",
    "data = { 'text': tokenize_posttrain(posttrain_tweets, 'embeddings'),\n",
    "         'labels': tokenize_posttrain(posttrain_tweets, 'response_label')\n",
    "       }\n",
    "t_posttrain = pd.DataFrame(data=data)\n",
    "t_posttrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054653df-19fa-42bf-a694-8f6058bf37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t_posttrain['text']\n",
    "y = t_posttrain['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54cfa0ee-f237-4622-98c5-e4e1431bc7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21035,\n",
       " 10,\n",
       " 8366,\n",
       " 8,\n",
       " 568,\n",
       " 149,\n",
       " 25,\n",
       " 54,\n",
       " 199,\n",
       " 16,\n",
       " 8,\n",
       " 647,\n",
       " 784,\n",
       " 439,\n",
       " 12038,\n",
       " 17717,\n",
       " 5042,\n",
       " 908,\n",
       " 24556,\n",
       " 23064,\n",
       " 34,\n",
       " 19,\n",
       " 310,\n",
       " 8299,\n",
       " 12,\n",
       " 11925,\n",
       " 3,\n",
       " 32,\n",
       " 115,\n",
       " 19864,\n",
       " 2936,\n",
       " 4527,\n",
       " 16,\n",
       " 39,\n",
       " 2554,\n",
       " 8519,\n",
       " 11483,\n",
       " 79,\n",
       " 43,\n",
       " 385,\n",
       " 22975,\n",
       " 15,\n",
       " 784,\n",
       " 17752,\n",
       " 3463,\n",
       " 4,\n",
       " 382,\n",
       " 908,\n",
       " 3862,\n",
       " 16736,\n",
       " 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53359af3-ec3c-4e74-b2d6-5d5844568570",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"data\", per_device_train_batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479f2d74-bcac-4d9c-b6e2-f6e070c804d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        self.x = x.values\n",
    "        self.y = y.values\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        item = { \n",
    "            'input_ids': x['input_ids'].squeeze(0),\n",
    "            'attention_mask': x['attention_mask'].squeeze(0),\n",
    "            'labels': y['input_ids'].squeeze(0),\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff7410e-57e6-4b12-bc31-8fe8809da97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,decoder_input_ids,decoder_attention_mask,head_mask,decoder_head_mask,cross_attn_head_mask,encoder_outputs,past_key_values,inputs_embeds,decoder_inputs_embeds,labels,use_cache,output_attentions,output_hidden_states,return_dict,labels,label_ids,label.\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d0bf4-f00d-4fa8-8679-e9c84c891a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8402b788-bc4e-4090-9572-e42a92b24d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "       model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cffe3a1-ef29-4179-8617-710086dd1c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 25\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20221128_021059-3ojg8a62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/natalieslittlehelper/huggingface/runs/3ojg8a62\" target=\"_blank\">data</a></strong> to <a href=\"https://wandb.ai/natalieslittlehelper/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99/1386854694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m             \u001b[0;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# Some issues here w/ CUDA, this will for future use \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f840b2-cd16-4a29-9e00-d87f8951aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_map(row):\n",
    "    context = row['negativereason']\n",
    "    # Were this a real pipeline, context would likely have information related to flights, luggage tracking, etc.\n",
    "    text = row['text']\n",
    "    tweet_input = create_tweet_input(context, text)\n",
    "    response = respond_to_tweet('', tokenizer, model, tweet_input, '')\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d674f-1cd9-4dfa-8a5d-7d78da49f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets.loc[0:1000, 'responses'] = neg_tweets.loc[0:1000].apply(response_map, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce76236e-8b21-448c-b68b-8deacabbd860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Do you have any recommendations on what else t...\n",
       "1                   How are they doing this right now?\n",
       "Name: responses, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets.loc[0:1000, 'responses'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe952c-bf1f-4b84-9731-daa5e325b440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
